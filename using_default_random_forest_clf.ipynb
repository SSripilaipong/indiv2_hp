{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from importlib import reload # used for debugging\n",
    "\n",
    "# local helper modules\n",
    "from load_data import load_data\n",
    "import data_prep as dprep\n",
    "\n",
    "import Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_prep' from '/home/shsnail/PycharmProjects/HomePro/data_prep/__init__.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used for debugging\n",
    "\n",
    "# reload(Preparation)\n",
    "# reload(dprep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Preparation.Preparation()\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('prep', prep),\n",
    "    ('clf', clf),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model with train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = load_data('expo_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df.loc[:, 'response_flag']\n",
    "X = df.drop('response_flag', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_transform\n",
      "(9800, 657)\n",
      "filled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('prep', <Preparation.Preparation object at 0x7fcb2cbc9208>), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform\n",
      "transform\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_prob = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scores(y_true, y_pred):\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    y_true = y_true.astype(bool)\n",
    "    y_pred = y_pred > 0.5\n",
    "    \n",
    "    TP = (y_pred & y_true).sum()\n",
    "    precision = TP/y_pred.sum()\n",
    "    recall = TP/y_true.sum()\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    accuracy = (y_pred == y_true).mean()\n",
    "    \n",
    "    return precision, recall, f1, accuracy, auc\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = scores(y_test.values, y_pred_prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision: 51.37 %\n",
      "   recall: 45.14 %\n",
      "f-measure: 48.05 %\n",
      "\n",
      " accuracy: 52.69 %\n",
      "      AUC: 53.88 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "precision: {:0.2f} %\n",
    "   recall: {:0.2f} %\n",
    "f-measure: {:0.2f} %\n",
    "\n",
    " accuracy: {:0.2f} %\n",
    "      AUC: {:0.2f} %\n",
    "'''.format(*map(lambda x: x*100, ss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_transform\n",
      "(9332, 635)\n",
      "filled\n",
      "isnull False\n",
      "transform\n",
      "transform\n",
      "transform\n",
      "transform\n",
      "fit_transform\n",
      "(9334, 665)\n",
      "filled\n",
      "isnull False\n",
      "transform\n",
      "transform\n",
      "transform\n",
      "transform\n",
      "fit_transform\n",
      "(9334, 712)\n",
      "filled\n",
      "isnull False\n",
      "transform\n",
      "transform\n",
      "transform\n",
      "transform\n"
     ]
    }
   ],
   "source": [
    "scorers = dict(\n",
    "    acc=make_scorer(accuracy),\n",
    "    auc=make_scorer(roc_auc_score)\n",
    ")\n",
    "cv = cross_validate(pipeline, X, y, scoring=scorers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shsnail/anaconda3/envs/datasci/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/shsnail/anaconda3/envs/datasci/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([32.48552918, 35.94692612, 61.8673842 ]),\n",
       " 'score_time': array([0.36811638, 0.61666703, 0.45040417]),\n",
       " 'test_acc': array([0.51949443, 0.53793399, 0.5327904 ]),\n",
       " 'test_auc': array([0.51949443, 0.53793399, 0.5327904 ]),\n",
       " 'train_acc': array([0.981033  , 0.98307264, 0.98167988]),\n",
       " 'train_auc': array([0.981033  , 0.98307264, 0.98167988])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that, by visualizing each tree used in random_forest, the model has only 10 trees with dramatic heights which mean the model is too overfit. to avoid the problem mentioned above, specifying the max_depth of the forest would be helpful.\n",
    "\n",
    "the trees are visulized and are stored in directory: `model/random_forest01/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
